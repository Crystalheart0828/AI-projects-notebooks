{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automate Market Research\n"
      ],
      "metadata": {
        "id": "tZ6h4xEoYJnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "Y-ZNdq9byXCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Automate Market Research Agent is a powerful tool that automates the process of collecting and organizing AI-related news articles. It performs two main functions:\n",
        "\n",
        "1.   Collecting relevant news articles using the **[News API](https://newsapi.org/)**\n",
        "2.   Organizing the content into Google Docs for easy access and analysis\n"
      ],
      "metadata": {
        "id": "D3JhZg7oydGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "lIicTA2Fyyhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before using the Automate Research Agent, you'll need:\n",
        "\n",
        "*   News API key\n",
        "\n",
        "##### **Google Cloud credentials with access to**:\n",
        "*   Google Sheets API\n",
        "\n",
        "If you don't know how to get your Google Cloud credentials, just ask any LLM the following prompt:\n",
        "\n",
        "\n",
        "```\n",
        "I am new to Google Cloud Console and haven't built a project yet.Could you please walk me through the step-by-step process to\n",
        "download the credentials file and activate the Google Sheets API?\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "##### **Python environment with the following packages**:\n",
        "*   newsapi-python\n",
        "*   google-auth\n",
        "*   google-api-python-client\n",
        "*   gspread\n",
        "*   requests\n"
      ],
      "metadata": {
        "id": "wAmENEoJyutK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step-by-Step Guide"
      ],
      "metadata": {
        "id": "oJ2i-ZZE0giH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1.   Setting Up Your Environment**"
      ],
      "metadata": {
        "id": "9vcuwIWr46C7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, configure your environment variables in Google Colab's \"Secrets\" section:\n",
        "\n",
        "*   **news_api**: Your NewsAPI key  \n",
        "*   **sheet_id**: ID of your Google Sheet\n",
        "*   **email_address**: Email for sharing documents  \n",
        "*   **folder_name**: Name for the research folder  \n",
        "*   **starting_date**: Start date for news collection  \n",
        "*   **ending_date**: End date for news collection  \n",
        "\n",
        "Also, Python environment with the following packages:"
      ],
      "metadata": {
        "id": "_iu1810p0ui7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install newsapi-python google-auth google-api-python-client gspread beautifulsoup4 requests"
      ],
      "metadata": {
        "id": "l2Hmf21I8Urj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import modules"
      ],
      "metadata": {
        "id": "ICO3J1M38ft2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from google.oauth2.service_account import Credentials\n",
        "from newsapi import NewsApiClient\n",
        "import json\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from googleapiclient.discovery import build\n",
        "from datetime import datetime\n",
        "\n",
        "import time\n",
        "\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "h87MI-jJYXm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the scope and authorize the Google credentials"
      ],
      "metadata": {
        "id": "-pOtAfGc8nh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the scope and authorize the credentials\n",
        "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "credentials_path = 'yourcrednentialpath.json'\n",
        "creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)"
      ],
      "metadata": {
        "id": "Vyx0W6kcYYvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize gspread client\n",
        "client = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "D8kzPPfAYapI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Collecting News Article**"
      ],
      "metadata": {
        "id": "qZZVatcreoKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think of this phase as having a team of researchers who search through news websites for you, but automated. Here's what happens:\n",
        "\n",
        "#### 1. Setting Your Search Topics\n",
        "- The script starts with a list of topics you want to research\n",
        "- For example, topics could be:\n",
        "  * Apple Inc.\n",
        "  * Google and Search\n",
        "  * Meta Ray-Ban\n",
        "  * Amazon\n",
        "  * Netflix\n",
        "\n",
        "#### 2. Defining Your Search Timeline\n",
        "- You specify two dates:\n",
        "  * A starting date: When you want to begin looking for news\n",
        "  * An ending date: The latest date for news articles\n",
        "- This helps focus on recent, relevant information. If you're in the free tier of NewsAPI\n",
        "\n",
        "#### 3. The Search Process\n",
        "- For each topic (like \"AI and marketing\"):\n",
        "  * The system connects to NewsAPI (think of it as a huge digital newspaper archive)\n",
        "  * It looks for English-language articles about that topic\n",
        "  * It organizes articles by relevance\n",
        "  * It can search through multiple pages of results (currently set to 5 pages)\n",
        "\n",
        "#### 4. Organizing the Results\n",
        "- For each topic, the system creates a separate sheet in your Google Spreadsheet\n",
        "- Each article entry includes:\n",
        "  * The article's title\n",
        "  * Author's name\n",
        "  * Source (which news website it's from)\n",
        "  * Publication date\n",
        "  * A brief description\n",
        "  * The article's URL\n",
        "  * A snippet of the content\n",
        "\n",
        "  </br>\n",
        "\n",
        "  Now let's start!"
      ],
      "metadata": {
        "id": "BoKS4RtM-gFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Connect NewsAPI"
      ],
      "metadata": {
        "id": "wWORvUb_YhDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "newsapi = NewsApiClient(api_key = userdata.get('news_api'))"
      ],
      "metadata": {
        "id": "0z7EAucwYbLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Build Functions"
      ],
      "metadata": {
        "id": "FRi3TWrKZ5zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Export to google sheet"
      ],
      "metadata": {
        "id": "AlYWnZCJZ73k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_google_sheet(all_articles, sheet_id, sheet_name):\n",
        "    # Open the Google Sheet and add a new worksheet or access an existing one\n",
        "    sheet = client.open_by_key(sheet_id)\n",
        "    try:\n",
        "        worksheet = sheet.worksheet(sheet_name)\n",
        "        worksheet.clear()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        worksheet = sheet.add_worksheet(title=sheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "    # Prepare the header\n",
        "    header = [\"Title\", \"Author\", \"Source\", \"Published At\", \"Description\", \"URL\", \"Content\"]\n",
        "    worksheet.append_row(header)\n",
        "\n",
        "    # Prepare the data rows for batch update\n",
        "    rows = []\n",
        "    for article in all_articles['articles']:\n",
        "        title = article.get('title', 'No Title')\n",
        "        author = article.get('author', 'No Author')\n",
        "        source = article['source']['name']\n",
        "        published_at = article.get('publishedAt')\n",
        "        description = article.get('description', 'No Description')\n",
        "        url = article.get('url', 'No URL')\n",
        "        content = article.get('content', 'No Content')\n",
        "\n",
        "        rows.append([title, author, source, published_at, description, url, content])\n",
        "\n",
        "    # Perform batch update\n",
        "    if rows:\n",
        "        worksheet.append_rows(rows)\n",
        "\n",
        "    print(f\"Articles exported successfully to the sheet: https://docs.google.com/spreadsheets/d/{sheet_id}/edit#gid={worksheet.id}\")\n"
      ],
      "metadata": {
        "id": "Ph_WN8SGZ47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. Query News API\n",
        "\n",
        "You can update the parameters to have advanced queries based on your need. Check [the official documentation](https://newsapi.org/docs/client-libraries/python) to know how it works."
      ],
      "metadata": {
        "id": "kY0WYFbzaI93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to query NewsAPI for a given keyword\n",
        "def query_news_api(keyword, starting_date, ending_date, pages):\n",
        "    all_articles = newsapi.get_everything(q=keyword,\n",
        "                                          sources=None,\n",
        "                                          domains=None,\n",
        "                                          from_param= starting_date,\n",
        "                                          to= ending_date,\n",
        "                                          language='en',\n",
        "                                          sort_by='relevancy',\n",
        "                                          page= pages)\n",
        "    return all_articles"
      ],
      "metadata": {
        "id": "nAWAZmdRYcJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### d. Process multiple keywords"
      ],
      "metadata": {
        "id": "8ubi1buebHkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_keywords(keywords, starting_date, ending_date, pages, sheet_id):\n",
        "    for keyword in keywords:\n",
        "        print(f\"Processing keyword: {keyword}\")\n",
        "        # Query the News API for the current keyword\n",
        "        all_articles = query_news_api(keyword, starting_date, ending_date, pages)\n",
        "\n",
        "        # Use the keyword directly as the sheet name\n",
        "        sheet_name = keyword  # Assuming the tab in the Google Sheet has the exact same name as the keyword\n",
        "\n",
        "        # Export the articles to the specific sheet/tab named after the keyword\n",
        "        export_to_google_sheet(all_articles, sheet_id, sheet_name)\n",
        "        print(f\"Finished processing for keyword: {keyword}\")"
      ],
      "metadata": {
        "id": "SFSJ9VPfYce0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### e.Run Main Function"
      ],
      "metadata": {
        "id": "jhGOZM7jbL8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    keywords = [\"Keyword A\",\"Keyword B\", \"Keyword C\", \"Keyword D\", \"Keyword E\"]\n",
        "    starting_date = userdata.get('starting_date')\n",
        "    ending_date = userdata.get('ending_date')\n",
        "    pages = 5\n",
        "    sheet_id = userdata.get('sheet_id')\n",
        "\n",
        "    process_keywords(keywords, starting_date, ending_date, pages, sheet_id)"
      ],
      "metadata": {
        "id": "tmCq855bYcuX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}